{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Baca file CSV\n",
    "df = pd.read_csv('cnbc_fix_dataset.csv')\n",
    "\n",
    "# Ubah nilai -1 menjadi 0 di kolom 'polarity'\n",
    "df['polarity'] = df['polarity'].replace(-1, 0)\n",
    "\n",
    "# Tampilkan beberapa baris pertama untuk memverifikasi perubahan\n",
    "print(df['polarity'].head())\n",
    "\n",
    "# Opsional: Simpan kembali ke file CSV\n",
    "df.to_csv('cnbc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Token</th>\n",
       "      <th>Stop_article</th>\n",
       "      <th>Stem_article</th>\n",
       "      <th>Prepos_article</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pemerintah tengah bersiap merealisasikan ekspo...</td>\n",
       "      <td>['pemerintah', 'tengah', 'bersiap', 'merealisa...</td>\n",
       "      <td>['pemerintah', 'merealisasikan', 'ekspor', 'pa...</td>\n",
       "      <td>perintah realisasi ekspor pasir laut presiden ...</td>\n",
       "      <td>['perintah', 'realisasi', 'ekspor', 'pasir', '...</td>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>direktur jenderal bea cukai kementerian keuang...</td>\n",
       "      <td>['direktur', 'jenderal', 'bea', 'cukai', 'keme...</td>\n",
       "      <td>['direktur', 'jenderal', 'bea', 'cukai', 'keme...</td>\n",
       "      <td>direktur jenderal bea cukai menteri uang askol...</td>\n",
       "      <td>['direktur', 'jenderal', 'bea', 'cukai', 'ment...</td>\n",
       "      <td>-39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ketua umum ikatan pengusaha konveksi berkarya ...</td>\n",
       "      <td>['jakarta', 'cnbc', 'indonesia', 'ketua', 'umu...</td>\n",
       "      <td>['jakarta', 'cnbc', 'indonesia', 'ketua', 'ika...</td>\n",
       "      <td>ketua ikat usaha konveksi karya ipkb nandi her...</td>\n",
       "      <td>['ketua', 'ikat', 'usaha', 'konveksi', 'karya'...</td>\n",
       "      <td>-58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pengusaha tekstil di dalam negeri menyoroti pe...</td>\n",
       "      <td>['pengusaha', 'tekstil', 'di', 'dalam', 'neger...</td>\n",
       "      <td>['pengusaha', 'tekstil', 'negeri', 'menyoroti'...</td>\n",
       "      <td>usaha tekstil negeri sorot nyata menteri uang ...</td>\n",
       "      <td>['usaha', 'tekstil', 'negeri', 'sorot', 'nyata...</td>\n",
       "      <td>-85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>presiden joko widodo jokowi memanggil beberapa...</td>\n",
       "      <td>['presiden', 'joko', 'widodo', 'jokowi', 'mema...</td>\n",
       "      <td>['presiden', 'joko', 'widodo', 'jokowi', 'mema...</td>\n",
       "      <td>presiden joko widodo jokowi panggil menteri ra...</td>\n",
       "      <td>['presiden', 'joko', 'widodo', 'jokowi', 'pang...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  pemerintah tengah bersiap merealisasikan ekspo...   \n",
       "1  direktur jenderal bea cukai kementerian keuang...   \n",
       "2  ketua umum ikatan pengusaha konveksi berkarya ...   \n",
       "3  pengusaha tekstil di dalam negeri menyoroti pe...   \n",
       "4  presiden joko widodo jokowi memanggil beberapa...   \n",
       "\n",
       "                                               Token  \\\n",
       "0  ['pemerintah', 'tengah', 'bersiap', 'merealisa...   \n",
       "1  ['direktur', 'jenderal', 'bea', 'cukai', 'keme...   \n",
       "2  ['jakarta', 'cnbc', 'indonesia', 'ketua', 'umu...   \n",
       "3  ['pengusaha', 'tekstil', 'di', 'dalam', 'neger...   \n",
       "4  ['presiden', 'joko', 'widodo', 'jokowi', 'mema...   \n",
       "\n",
       "                                        Stop_article  \\\n",
       "0  ['pemerintah', 'merealisasikan', 'ekspor', 'pa...   \n",
       "1  ['direktur', 'jenderal', 'bea', 'cukai', 'keme...   \n",
       "2  ['jakarta', 'cnbc', 'indonesia', 'ketua', 'ika...   \n",
       "3  ['pengusaha', 'tekstil', 'negeri', 'menyoroti'...   \n",
       "4  ['presiden', 'joko', 'widodo', 'jokowi', 'mema...   \n",
       "\n",
       "                                        Stem_article  \\\n",
       "0  perintah realisasi ekspor pasir laut presiden ...   \n",
       "1  direktur jenderal bea cukai menteri uang askol...   \n",
       "2  ketua ikat usaha konveksi karya ipkb nandi her...   \n",
       "3  usaha tekstil negeri sorot nyata menteri uang ...   \n",
       "4  presiden joko widodo jokowi panggil menteri ra...   \n",
       "\n",
       "                                      Prepos_article  polarity_score  polarity  \n",
       "0  ['perintah', 'realisasi', 'ekspor', 'pasir', '...             -12         0  \n",
       "1  ['direktur', 'jenderal', 'bea', 'cukai', 'ment...             -39         0  \n",
       "2  ['ketua', 'ikat', 'usaha', 'konveksi', 'karya'...             -58         0  \n",
       "3  ['usaha', 'tekstil', 'negeri', 'sorot', 'nyata...             -85         0  \n",
       "4  ['presiden', 'joko', 'widodo', 'jokowi', 'pang...              15         1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Anjelita\n",
      "[nltk_data]     Malik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing and padding sequences\n",
    "max_features = 2000  # Adjust as necessary\n",
    "max_length = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(df['Stem_article'].values)\n",
    "\n",
    "# Convert texts to sequences\n",
    "X = tokenizer.texts_to_sequences(df['Stem_article'].values)\n",
    "X = pad_sequences(X, padding='post', maxlen=max_length)\n",
    "\n",
    "# Convert labels to a format acceptable by Keras\n",
    "Y = pd.get_dummies(df['polarity'])\n",
    "labels = Y.columns\n",
    "Y = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contoh hasil tokenisasi dan padding:\n",
      "[  15  235   10  231   80  375  402   96   18   18   15  548   68  181\n",
      "   22  231   18  535 1164  147  231  482  118   32  529 1022  712  174\n",
      "  254    5   23 1031 1080    5  231  555 1301   35  102   30    3    2\n",
      "    5    6  251 1070  452  518   16    4  678  658  477  954  529   71\n",
      "  174   87  125  153    5   23 1031 1080  836  231   10   69  290  869\n",
      "  252  147  407   96  678   76   27  535  571  568    5   10   20  252\n",
      "   22  168   26  932 1670   98  168  870  932  258  645  369 1607  285\n",
      "  932  100 1671  390  932  754  390  820   20  933  369  955  390  249\n",
      "  369  407   18  663   15 1155   18 1412  891 1608  777   95   46  231\n",
      "  231  965  121   19  188  975  777  145  184  206 1609  249 1610    5\n",
      "  231  555 1301  188  231   19  464 1637    4  976 1032  976 1032 1637\n",
      " 1965  249  976 1032  177 1056 1194   10  231  348 1314  231    4  249\n",
      "  947  249  489  231  194  175 1920  927  490  548   96  257  217   53\n",
      "   10  231  235   15  535   37  562   32    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "[ 102   30    3    2    5    6  251 1490 1195  431  247   69    3    2\n",
      "  736 1490 1195  205  188  202    2   18   18    5  251   87  928   32\n",
      "  125  153  251  132  247  513  188  202   21  579  264  496   10  513\n",
      "  787   60  425  563  188   21  251  621  513   63  247   19  535  192\n",
      "   32  111  535  111  421  496  395  431  247    4  208  431 1367 1195\n",
      "  277  432  325 1701 1348    4 1777 1111 1833  205  431  208 1165  247\n",
      " 1165  247    7  755 1081    7   15  595   26    3    2  408  689  689\n",
      "   48    3    2    5    6   69  205  145 1195  208   16   40  998    7\n",
      "   52   14   27   33   39   33   39   28   33   39 1111    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "[ 277  756   16 1033 1071    7  200 1165    7  286   63  524  313  675\n",
      "   72   55   19  679   42    7    9   20 1873  182  238   78  153  339\n",
      "    7   20    9  503   46    9  126  452    7 1315  177  480    3   20\n",
      " 1611    3  773   46    9    1    9  503   16   16   83  513  625 1196\n",
      "    7   16 1316  871 1195  208  219   16  247  766   55   19   29  220\n",
      "   73    4  130  472 1126  169   70  464   55  294  314  514   55 1834\n",
      "   55  519    4  600  277  432  325 1701 1348    4 1777 1111 1833 1491\n",
      "   15 1331  152    7 1874   69  290   98    7  821  872 1218  112  336\n",
      "  651 1612    7  236  668 1139   15  405 1081    7  272   18    5   23\n",
      "  161  268  156  436   18    5   23  268   53   18  269  680  215  113\n",
      "  630  113  100    3    2  467   70  873  356  340  243 1111    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Display some samples of tokenization results\n",
    "print(\"Contoh hasil tokenisasi dan padding:\")\n",
    "for i in range(3):\n",
    "    print(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anjelita Malik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 150\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim, input_length=X.shape[1]))\n",
    "model.add(Bidirectional(LSTM(256, dropout=0.2, return_sequences=True)))\n",
    "model.add(LSTM(128, dropout=0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(Y_train.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.0000e+00 - loss: 0.7015\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">300,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">833,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">328,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m150\u001b[0m)          │       \u001b[38;5;34m300,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m512\u001b[0m)          │       \u001b[38;5;34m833,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │       \u001b[38;5;34m328,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,459,880</span> (17.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,459,880\u001b[0m (17.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,486,626</span> (5.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,486,626\u001b[0m (5.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,973,254</span> (11.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,973,254\u001b[0m (11.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Force the model to build by training on a small batch of real data\n",
    "model.fit(X_train[:1], Y_train[:1], epochs=1, batch_size=1, verbose=1)\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.6709 - loss: 0.6386 - val_accuracy: 0.7675 - val_loss: 0.5503\n",
      "Epoch 2/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.7045 - loss: 0.6130 - val_accuracy: 0.7591 - val_loss: 0.5547\n",
      "Epoch 3/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - accuracy: 0.7365 - loss: 0.5835 - val_accuracy: 0.7675 - val_loss: 0.5650\n",
      "Epoch 4/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.7209 - loss: 0.5968 - val_accuracy: 0.7647 - val_loss: 0.6030\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "# Membuat callback EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metrik yang dipantau (bisa juga 'val_accuracy')\n",
    "    patience=3,          # Jumlah epoch untuk menunggu sebelum berhenti jika tidak ada perbaikan\n",
    "    min_delta=0.001,     # Perubahan minimum yang dianggap sebagai perbaikan\n",
    "    mode='min',          # 'min' untuk loss, 'max' untuk accuracy\n",
    "    restore_best_weights=True  # Mengembalikan bobot terbaik yang ditemukan selama pelatihan\n",
    ")\n",
    "\n",
    "# Menambahkan callback ke model.fit\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=epochs,  # Jumlah maksimum epoch\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[early_stopping],  # Menambahkan callback\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 525ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       274\n",
      "           1       0.00      0.00      0.00        83\n",
      "\n",
      "    accuracy                           0.77       357\n",
      "   macro avg       0.38      0.50      0.43       357\n",
      "weighted avg       0.59      0.77      0.67       357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anjelita Malik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Anjelita Malik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Anjelita Malik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test.argmax(axis=1), pred.argmax(axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
